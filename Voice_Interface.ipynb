{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18O9bMwSb9r2"
   },
   "source": [
    "## Notebook for converting speect to text; chatbot usage; convert text to speech back.\n",
    "\n",
    "* Using Whisper package from OpenAI to convert speect to Text which is used as iput to chat model.\n",
    "* Using LangChain to train/clone chatgpt model\n",
    "* Using google's gTTS package to convert text(output of model) to speech again.\n",
    "* You can use any mp4 files by recording your prompt using a voice recorder on your laptop. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fAIMJdhx72y"
   },
   "source": [
    "Speech to text conversaion using Whisper from OpenAI. Using a recording that I did with windows default voice recorder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = r'your_Dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ykqIY5PF0r-1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\vnirwan\\appdata\\local\\temp\\1\\pip-req-build-khxaz5qc\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numba in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (0.59.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (2.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (4.66.4)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (10.1.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from openai-whisper==20231117) (0.7.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from numba->openai-whisper==20231117) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper==20231117) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper==20231117) (2.32.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20231117) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20231117) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20231117) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20231117) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->openai-whisper==20231117) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->openai-whisper==20231117) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->openai-whisper==20231117) (2021.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\vnirwan\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\vnirwan\\AppData\\Local\\Temp\\1\\pip-req-build-khxaz5qc'\n",
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!sudo apt update && sudo apt install ffmpeg #install command-line tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "anlrdcxI1KXT"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "model= whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "J8x8_Lxwx6hU",
    "outputId": "7d2c1da5-851d-4aab-f080-7c4ea236e578"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I want you to act like a primary school teacher who teaches moral values which is the most important moral value.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #load the base model\n",
    "first_prompt=whisper.load_audio(\"first_prompt.m4a\")\n",
    "first_prompt=whisper.pad_or_trim(first_prompt) #trims the audio to 30sec\n",
    "#\n",
    "mel=whisper.log_mel_spectrogram(first_prompt).to(model.device)\n",
    "options=whisper.DecodingOptions(fp16=False)\n",
    "result=whisper.decode(model,mel,options)\n",
    "first_prompt=result.text #This is the text we will use to input in our trained Chatbot\n",
    "first_prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1xw19OiySw-"
   },
   "source": [
    "Using Langchain to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgkl7X1vyV4n"
   },
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install openai\n",
    "import os\n",
    "#This is a paid account.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" #using my openAI account key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWOkeAZ4h-0L"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHUGxJ2CiUI2"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtRxvJGLi5QU"
   },
   "outputs": [],
   "source": [
    "chain.run(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghw6VHfsygxu"
   },
   "source": [
    "There are multiple types of memory that can be in ConversationChain:\n",
    "\n",
    "ConversationBufferMemory\n",
    "ConversationSummaryMemory\n",
    "ConversationBufferWindowMemory\n",
    "ConversationSummaryBufferMemory\n",
    "\n",
    "Using converationchain and using ConversationBufferMemory : a simple type of memory that remembers all previous inputs/outputs and adds them to the context that is passed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdkarRnNy7C8"
   },
   "source": [
    "## Clone ChatGPT\n",
    "This chain replicates ChatGPT by combining\n",
    "* a specific prompt\n",
    "* the concept of memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ky1CCQB_1-Sw",
    "outputId": "d9763f82-df12-4910-bc49-c21eea3b82bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: I want you to act like a primary school teacher who teaches moral values which is the most important moral value.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "response_first=conversation.predict(input=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIzfa-uPhbNH",
    "outputId": "d83d94f7-2b27-40ee-eaef-1a5d260343c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.chains.conversation.base.ConversationChain"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qdZZbxnklfD"
   },
   "outputs": [],
   "source": [
    "#from langchain.chains.conversation.memory import ConversationalBufferWindowMemory\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mRpqcJFgy8u6",
    "outputId": "9ecadb99-60c4-41dc-e5c1-3a1ccfeb8275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAssistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "\n",
      "Kid: I want you to act like a primary school teacher who teaches moral values. Which is the most important moral value?\n",
      "Teacher:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Respect is the most important moral value. Respect for yourself, respect for others, and respect for the environment are all essential for living a moral life. Respect is the foundation of all other moral values, and it is important to remember that respect is not just about treating others well, but also about treating yourself with respect.\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain, LLMChain, PromptTemplate\n",
    "#from langchain.chains.conversation.memory import ConversationalBufferWindowMemory\n",
    "#from langchain.chains.conversation.memory import ConversationSummaryBufferMemory # Summarize previous conversation while passing exact prompt of some conversations\n",
    "\n",
    "\n",
    "template = \"\"\"Assistant is a large language model trained by OpenAI.\n",
    "\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "\n",
    "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
    "\n",
    "{history}\n",
    "Kid: {human_input}\n",
    "Teacher:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"human_input\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "my_llm=OpenAI(temperature=0) #wants to take less risk with predictions\n",
    "my_memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=2)\n",
    "chatgpt_chain = LLMChain(\n",
    "    llm=my_llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True, #To see the prompt. In final model set this to false\n",
    "    memory = my_memory #Remembers upto 2 recent converations\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "HTrCJfeDnBrj",
    "outputId": "d8f65d9c-5f71-445e-d098-7fc43fe1353f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I want you to act like a primary school teacher who teaches moral values which is the most important moral value.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXLRSH60mKIE",
    "outputId": "c68c83d3-c60a-4de5-d5ce-ea7dd1129600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAssistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "System: \n",
      "The human asked the AI to act like a primary school teacher who teaches moral values. The AI responded that respect is the most important moral value, as it is the foundation of all other moral values and involves treating both others and oneself with respect, including treating others with kindness, understanding, and fairness, and taking care of oneself and making sure to do what is right. Respect is the key to building strong relationships and creating a better world.\n",
      "Kid: I want you to act like a primary school teacher who teaches moral values which is the most important moral value.\n",
      "Teacher:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Respect is the most important moral value. Respect involves treating both others and oneself with respect, including treating others with kindness, understanding, and fairness, and taking care of oneself and making sure to do what is right. Respect is the key to building strong relationships and creating a better world.\n"
     ]
    }
   ],
   "source": [
    "bot_first_res = chatgpt_chain.predict(human_input=first_prompt)\n",
    "print(bot_first_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeM4bsMx8t2S"
   },
   "source": [
    "## Converting text to speech\n",
    "Pytsx is a cross-platform text-to-speech wrapper.\n",
    "It uses different speech engines based on your operating system:\n",
    "\n",
    "nsss - NSSpeechSynthesizer on Mac OS X 10.5 and higher\n",
    "\n",
    "sapi5 - SAPI5 on Windows XP, Windows Vista, and (untested) Windows 7\n",
    "\n",
    "espeak - eSpeak on any distro / platform that can host the shared library (e.g., Ubuntu / Fedora Linux)\n",
    "Install with pip (using pyenv, pipenv or virtualenv):\n",
    "\n",
    "sudo pip install pyttsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaM_tXbZmSk2"
   },
   "outputs": [],
   "source": [
    "!sudo pip install pyttsx\n",
    "!sudo pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QL5z9vcf9LNi"
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "tts = gTTS(text=bot_first_res, lang='en')\n",
    "tts.save(\"bot_first_res.m4a\") #response from chat model\n",
    "#os.system(\"response_first.m4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pXIDHQLmsTA"
   },
   "source": [
    "You can download bot_first_res and play it on your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAA3eH48mztR"
   },
   "source": [
    "Using 2nd prompt which is a follow up question to chatbot's 1st answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6q0T6cInnSLG"
   },
   "source": [
    "First conversting 2nd response from human to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VB5YiUcyfeEF"
   },
   "outputs": [],
   "source": [
    "#Second prompt\n",
    "sec_prompt=whisper.load_audio(\"Prompt2.m4a\")\n",
    "sec_prompt=whisper.pad_or_trim(sec_prompt) #trims the audio to 30sec\n",
    "#\n",
    "sec_mel=whisper.log_mel_spectrogram(sec_prompt).to(model.device)\n",
    "sec_options=whisper.DecodingOptions(fp16=False)\n",
    "sec_result=whisper.decode(model,sec_mel,sec_options)\n",
    "sec_prompt=sec_result.text #This is the text we will used as 2nd prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "k85EZO_FmZzP",
    "outputId": "7d5340d1-2fb7-448c-d4ad-cb36d5eea6b4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'How can I apply this value to my friends?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMyjtby-nbmo"
   },
   "source": [
    "Input this 2nd response to chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "Ij7rd3Babld9",
    "outputId": "549d5f71-19b7-4624-ebcb-fc6173154cd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAssistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "System: \n",
      "The human asked the AI to act like a primary school teacher who teaches moral values. The AI responded that respect is the most important moral value, as it is the foundation of all other moral values and involves treating both others and oneself with respect, including treating others with kindness, understanding, and fairness, and taking care of oneself and making sure to do what is right. Respect is the key to building strong relationships and creating a better world.\n",
      "Kid: How can I apply this value to my friends?\n",
      "Teacher:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' Respect is the foundation of any strong relationship, so it is important to show respect to your friends. This means treating them with kindness, understanding, and fairness, and listening to their opinions and ideas. It also means being honest and open with them, and being willing to compromise and work together to find solutions to any problems that arise. Respect also means being supportive and encouraging of your friends, and being there for them when they need you.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_chain.predict(human_input=sec_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QC6wz6donfxU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
